{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-Step Guide: Implementing Transfer Learning with EfficientNet\n",
    "Ok, let’s now proceed with the actual implementation. We’ll go over the whole process step by step! Note that we provide really detailed comment for each code line we provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we also imported to_categorical function that would let us convert the targets (classes that we try to classify) to one-hot-encoded vectors that we can use to fine-tune our CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fashion MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = \\\n",
    "    fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take just the first 1k images of this dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images[:1000]\n",
    "train_labels = train_labels[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the question is: how can we move from 1k 28 by 28 grayscale images to 1k 224 by 224 RGB images? Well, in TensorFlow & Keras it isn’t that hard! All we need to do add the third channel to all of the images and reshape them! So, if we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.expand_dims(train_images, axis=-1) #expand_dims() function we added the 3rd channel needed for EfficientNet-B0,\n",
    "test_images = tf.expand_dims(test_images, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the images again (224 x 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.image.grayscale_to_rgb(train_images)\n",
    "train_images = tf.image.resize(train_images, (224, 224))\n",
    "\n",
    "test_images = tf.image.grayscale_to_rgb(test_images)\n",
    "test_images = tf.image.resize(test_images, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize our images to the range [0, 1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels to one-hot encoded ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next sum everything up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load Fashion MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Getting only 1k from the training portion of data\n",
    "train_images = train_images[:1000]\n",
    "train_labels = train_labels[:1000]\n",
    "\n",
    "# Reshape the images to include the channel dimension (since EfficientNet expects 3D input)\n",
    "train_images = tf.expand_dims(train_images, axis=-1)\n",
    "test_images = tf.expand_dims(test_images, axis=-1)\n",
    "\n",
    "# Resize images to match EfficientNet input size (224x224) and convert to 3 channels\n",
    "train_images = tf.image.grayscale_to_rgb(train_images)\n",
    "train_images = tf.image.resize(train_images, (224, 224))\n",
    "\n",
    "test_images = tf.image.grayscale_to_rgb(test_images)\n",
    "test_images = tf.image.resize(test_images, (224, 224))\n",
    "\n",
    "# Normalize images to the range [0, 1]\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Import the Pre-Trained EfficientNetB0 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the EfficientNetB0 model, excluding the top classification layers\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False,\n",
    "                            input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model to retain its pre-trained weights\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Building the Custom Top Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EfficientNet model will act as a feature extractor, meaning that it will extract information from the images but do not do the actual classification decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom top layer\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),  # Converts the feature maps into a single vector\n",
    "    layers.Dense(128, activation='relu'),  # Add a fully connected layer with 128 neurons\n",
    "    layers.Dense(10, activation='softmax')  # Final layer with 10 outputs for 10 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 702ms/step - accuracy: 0.1043 - loss: 2.3538 - val_accuracy: 0.0950 - val_loss: 2.3265\n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 665ms/step - accuracy: 0.0983 - loss: 2.3196 - val_accuracy: 0.1070 - val_loss: 2.3144\n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 669ms/step - accuracy: 0.1045 - loss: 2.3099 - val_accuracy: 0.0950 - val_loss: 2.3089\n",
      "Epoch 4/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 679ms/step - accuracy: 0.1043 - loss: 2.3052 - val_accuracy: 0.0950 - val_loss: 2.3065\n",
      "Epoch 5/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 706ms/step - accuracy: 0.1160 - loss: 2.3074 - val_accuracy: 0.0950 - val_loss: 2.3117\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=5,\n",
    "                    validation_data=(test_images[:1000],\n",
    "                    test_labels[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Fine-Tuning the Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 3s/step - accuracy: 0.2173 - loss: 2.2461 - val_accuracy: 0.1110 - val_loss: 2.3187\n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.2364 - loss: 1.9961 - val_accuracy: 0.1110 - val_loss: 2.3156\n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.2759 - loss: 1.7907 - val_accuracy: 0.1110 - val_loss: 2.3159\n",
      "Epoch 4/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.3913 - loss: 1.5944 - val_accuracy: 0.1110 - val_loss: 2.3264\n",
      "Epoch 5/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 2s/step - accuracy: 0.4756 - loss: 1.4894 - val_accuracy: 0.0660 - val_loss: 2.3305\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model\n",
    "history_fine = model.fit(train_images, train_labels, epochs=5, validation_data=(test_images[:1000], test_labels[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the model evaluation without fine-tuning that we’ve done above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 320ms/step - accuracy: 0.0692 - loss: 2.3225\n",
      "Test accuracy: 6.60\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_images[:1000],\n",
    "        test_labels[:1000])\n",
    "\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
